{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Testing\n",
    "\n",
    "There are several forms of testing, that we'll try to summarize here. Other sources might use different names for the same thing, although the ideas behind are often the same:\n",
    "\n",
    "## Unit testing\n",
    "\n",
    "This is a test that focus on a very small fraction of the code (what's called a *unit* of code, hence the name). This form of testing validates that every piece works as expected on its own, but it doesn't test that all pieces actually work together. Unit tests are often grouped into **Test suites**. For instance, you could have a test suite to unit test a single class, where every method of that class is tested through one or more unit tests.\n",
    "\n",
    "Now, unit tests must meet some requirements:\n",
    "\n",
    "- **Isolation**: The focus for a unit test is on the logic, so it shouldn't depend on anything outside the code (e.g. databases connections, local files, etc). On top of that, the tests should not depend on each other: your test should work independently of other tests.\n",
    "\n",
    "- **Self-validating**: The result of a unit test is known as soon of the test finishes, no extra steps are needed (specially no manual steps)\n",
    "\n",
    "- **Performance**: In general, unit tests are expected to be relatively quick (at worst, a unit test should execution time should be in the order of seconds). The reason for this is that unit tests are meant to be run very often, in an automated way, so you don't want this process to take hours.\n",
    "\n",
    "## Other types of (automated) tests\n",
    "\n",
    "Although you might find the same ideas with different names in other resources, here are other common forms of testing. The ideas behind it should be the same even if names might differ a bit:\n",
    "\n",
    "- **Integration test**: The main goal of integration tests is to cover what unit tests doesn't: testing multiple components together. An integration test will validate multiple components together. They often break the isolation in the sense that they might use multiple components in parallel, meaning that when one of these tests fails, you might not be sure of which component exactly is the one that broke.\n",
    "\n",
    "- **System tests**: These are often called integration tests as well, and one might argue that they are actually the same. The main twist here is that not only several components or pieces of code are tested together, but that the actual infrastructure is used (e.g. data, files, etc)\n",
    "\n",
    "- **Acceptance test**: This type of test is run from the perspective of the user, so in general they try to mimic what a user would do rather than what a developer expects the application to do.\n",
    "\n",
    "## When to use which type?\n",
    "\n",
    "Ideally, you should use a combination of the different types, although probably the most extended type of automated testing are unit tests, and to some extent, integration / system tests.\n",
    "\n",
    "The main benefit of unit tests is that you can find lots of bugs in your code before they ever happen, and if you adhere to some of the methodologies (e.g. TDD - Test Driven Design), you won't have code that you are not using. The downside is that as much as you test, you can't be 100% sure that the application will actually work once it is deployed, or even when working together with other modules. That's where the other types of tests are handy, since they don't really care of the exact code, they rather focus on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing methodologies\n",
    "\n",
    "Currently, there are three main testing methodologies: TDD (Test Driven Development), BDD (Behavior Driven Development) and DDD (Domain Driven Development). We will focus on the first one, TDD, and just give a quick introduction to what the other two types are.\n",
    "\n",
    "## Test Driven Development\n",
    "\n",
    "Formally, TDD is the process of writing a test before you actually write the code. This way, you are defining what the new code is supposed to do and under what conditions. The main benefit of this approach: you won't write code that you don't need, and your tests can serve as documentation / examples on how to use the code.\n",
    "\n",
    "This is how the TDD development cycle looks like:\n",
    "\n",
    "![TDD Development Cycle](../../images/tdd_cycle.jpg \"TDD Development Cycle\")\n",
    "\n",
    "Python ships a library for unit testing out of the box, the [```unittest``` module](https://docs.python.org/3/library/unittest.html), but probably the most extended libraries for testing in Python is [pytest](https://docs.pytest.org/en/latest/) which we'll be using through this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with TDD, you are always iterating over the three steps:\n",
    "\n",
    "### RED\n",
    "\n",
    "At this stage, your goal is simple: write a failing unit test. That said, the test should still be complete in the sense that it should reflect what's actually expected from the code. For instance, imagine you want write a function that adds two to any number you provide. Its test could look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_add_two():\n",
    "    result = add_two(1)\n",
    "\n",
    "    assert result == 3, \"The result of adding 2 to 1 should be 3!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that our test is actually failing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The result of adding 2 to 1 should be 3!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-dd943a0eafed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_add_two\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-57f955443dc1>\u001b[0m in \u001b[0;36mtest_add_two\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_two\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"The result of adding 2 to 1 should be 3!\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: The result of adding 2 to 1 should be 3!"
     ]
    }
   ],
   "source": [
    "test_add_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GREEN\n",
    "\n",
    "In the Green part of the cycle, your goal is to write the MINIMUM code that passes the function. For very simple cases, you might be able to write the \"optimum\" code straight away, but keeping it to the minimum will help you in not having code you don't need.\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "What's the minimum code you need in the ```add_two``` function to pass this test? To get started, we need to create the function itself, but we also need to add the code into it that will make the test pass.\n",
    "\n",
    "**HINT**: Make sure you write the MINIMUM code you need to pass this single test.\n",
    "\n",
    "Implement it in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "def add_two(number):\n",
    "    # START YOUR CODE HERE\n",
    "    pass\n",
    "    # END YOUR CODE HERE\n",
    "\n",
    "test_add_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "Although it might seem counter-intuitive at the beginning (specially in an example that's so easy to implement in a way that already works for any argument), sticking to the minimum code you need will help you in more complex cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_add_two succeeded, adding 2 to 1 is 3!\n"
     ]
    }
   ],
   "source": [
    "def add_two(number):\n",
    "    return 3\n",
    "\n",
    "test_add_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REFACTOR\n",
    "\n",
    "The last phase, the refactor phase, is meant as a \"cleanup\" phase. The goal here is to consolidate / improve the code you just wrote, **without changing its behaviour**. In practice this might come down to adding documentation, moving duplicated code to another function, etc..\n",
    "\n",
    "#### Exercise\n",
    "Refactor the ```add_two``` function however you see fit. Remember: try not to change its behaviour. Given that the function is pretty simple, you might not have a lot of refactor to do, but you could check, for instance, whether you have documented the function, and/or whether you have added type hints for the argument and the return type, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# START YOUR CODE HERE\n",
    "def add_two(number):\n",
    "    pass\n",
    "# END YOUR CODE HERE\n",
    "\n",
    "# The test still needs to pass\n",
    "test_add_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "As we mentioned, there was not a lot of code to add in our fancy function. However, we didn't have any type hinting or documentation for it, so that's what we'll be adding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "def add_two(number: int) -> int:\n",
    "    \"\"\"This function just adds 2 to any number it receives\"\"\"\n",
    "    return 3\n",
    "\n",
    "test_add_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The AAA pattern - Arrange, Act, Assert\n",
    "\n",
    "This pattern is probably the most extended one when writing tests. Although there's no golden rule on how to write tests, this pattern helps to keep a good structure in your tests, and since it's commonly used, it makes it easier for people to understand yoru code.\n",
    "\n",
    "The pattern states that you should \"split\" your test in three sections:\n",
    "\n",
    "- **Arrange**. Here you are setting up everything you need to run your test. This might include defining the values for the arguments you will use, the expected return value for your function, and setting up any other context that your test might need (we'll see more on this later).\n",
    "\n",
    "- **Act**: In the *act* block, we'll be calling our code, and if applicable, we'll collect the result that we'll be checking later.\n",
    "\n",
    "- **Assert**: Last but not least, we need to validate that our result is what we expect. Very often, this means just asserting that your result is correct, but in more complex cases, you might want to check extra things (e.g. a certain file was created)\n",
    "\n",
    "Further reading: https://medium.com/@pjbgf/title-testing-code-ocd-and-the-aaa-pattern-df453975ab80\n",
    "\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "Can you rewrite the ```test_add_two``` function we have to follow the AAA pattern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "def test_add_two():\n",
    "    # START CODE HERE\n",
    "    result = add_two(1)\n",
    "\n",
    "    assert result == 3, f\"The result of adding 2 to 1 should be 3, but it was {result}!\"\n",
    "    # END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "def test_add_two():\n",
    "    number = 1\n",
    "    expected_result = 3\n",
    "    \n",
    "    result = add_two(number)\n",
    "\n",
    "    assert result == expected_result, \\\n",
    "        f\"The result of adding 2 to {number} should be {expected_result}, but it was {result}!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "Hopefully the three blocks are clear enough. We didn't add any comments of which block is which, because as soon as you \"interiorize\" the AAA pattern, these comments become just clutter, they don't provide any extra value to your code. If it helps you at the beginning, feel free to add comments to have some sort of \"template\" for your tests:\n",
    "\n",
    "```python\n",
    "def test_add_two():\n",
    "    # Arrange\n",
    "    number = 1\n",
    "    expected_result = 3\n",
    "    \n",
    "    # Act\n",
    "    result = add_two(number)\n",
    "\n",
    "    # Assert\n",
    "    assert result == expected_result, f\"The result of adding 2 to {number} should be {expected_result}!\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the \"minimum code needed\"\n",
    "\n",
    "In this example, it might seem counter-intuitive, or even counter-productive, to just return 3 like we're doing:\n",
    "\n",
    "```python\n",
    "def add_two(number: int) -> int:\n",
    "    \"\"\"This function just adds 2 to any number it receives\"\"\"\n",
    "    return 3\n",
    "\n",
    "test_add_two()\n",
    "```\n",
    "\n",
    "It is very clear that what we'll need in the end is a function that returns ```number + 2```. That's correct, and for this simple case it would still pass your test (and any other test case with a valid number). In more complex cases, though, you might end up implementing logic that will never be used.\n",
    "\n",
    "### So, at what point should you generalize?\n",
    "\n",
    "As with most things: there's no absolute rule. However, a rule of thumb that you can use to get an intuition about when to generalize, and that at the same time can make it easier to write code that works for any value, is the following:\n",
    "\n",
    "- Write the code to pass for 1 value\n",
    "- Next time (i.e. when you get a new test), write the code to pass for two values\n",
    "- Next time (when you get yet another test), write code that works for any number of values.\n",
    "\n",
    "#### Exercise 1 - Pass for two tests\n",
    "\n",
    "In our next iteration, we get an extra test that we need to pass. Your goal is to adapt the ```add_two``` function so that both tests pass. We have done the RED part for you, so you already have a failing test, ```test_add_two_to_3```. Now, make it GREEN, and REFACTOR if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The result of adding 2 to 3 should be 5!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e9b9c6a87360>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mtest_add_two\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mtest_add_two_to_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-e9b9c6a87360>\u001b[0m in \u001b[0;36mtest_add_two_to_3\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_two\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mexpected_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"The result of adding 2 to {number} should be {expected_result}!\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mtest_add_two\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: The result of adding 2 to 3 should be 5!"
     ]
    }
   ],
   "source": [
    "def test_add_two():\n",
    "    number = 1\n",
    "    expected_result = 3\n",
    "    \n",
    "    result = add_two(number)\n",
    "\n",
    "    assert result == expected_result, \\\n",
    "        f\"The result of adding 2 to {number} should be {expected_result}, but it was {result}!\"\n",
    "\n",
    "def test_add_two_to_3():\n",
    "    number = 3\n",
    "    expected_result = 5\n",
    "    \n",
    "    result = add_two(number)\n",
    "    \n",
    "    assert result == expected_result, \\\n",
    "        f\"The result of adding 2 to {number} should be {expected_result}, but it was {result}!\"\n",
    "\n",
    "test_add_two()\n",
    "test_add_two_to_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "def add_two(number: int) -> int:\n",
    "    \"\"\"This function just adds 2 to any number it receives\"\"\"\n",
    "    # START CODE HERE\n",
    "    return 3\n",
    "    # END CODE HERE\n",
    "\n",
    "test_add_two()\n",
    "test_add_two_to_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "This is our second test, so sticking to our rule of thumb, we won't be generalizing yet, we will just adapt our code to pass both test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "def add_two(number: int) -> int:\n",
    "    \"\"\"This function just adds 2 to any number it receives\"\"\"\n",
    "    # START CODE HERE\n",
    "    if number == 1:\n",
    "        return 3\n",
    "    else:\n",
    "        return 5\n",
    "    # END CODE HERE\n",
    "\n",
    "test_add_two()\n",
    "test_add_two_to_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2 - Pass for n tests\n",
    "\n",
    "Finally, it seems like our ```add_two``` function is really getting traction, and we get yet another test case, to be sure it works even for negative numbers. Like before, we're giving you the RED part; a failing test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The result of adding 2 to -6 should be -4, but it was 5!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-cbab7914d4bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtest_add_two\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtest_add_two_to_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtest_add_two_to_minus_6\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-cbab7914d4bf>\u001b[0m in \u001b[0;36mtest_add_two_to_minus_6\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mexpected_result\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;34mf\"The result of adding 2 to {number} should be {expected_result}, but it was {result}!\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtest_add_two\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: The result of adding 2 to -6 should be -4, but it was 5!"
     ]
    }
   ],
   "source": [
    "def test_add_two_to_minus_6():\n",
    "    number = -6\n",
    "    expected_result = -4\n",
    "    \n",
    "    result = add_two(number)\n",
    "    \n",
    "    assert result == expected_result, \\\n",
    "        f\"The result of adding 2 to {number} should be {expected_result}, but it was {result}!\"\n",
    "\n",
    "test_add_two()\n",
    "test_add_two_to_3()\n",
    "test_add_two_to_minus_6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "def add_two(number: int) -> int:\n",
    "    \"\"\"This function just adds 2 to any number it receives\"\"\"\n",
    "    # START CODE HERE\n",
    "    return 3\n",
    "    # END CODE HERE\n",
    "\n",
    "test_add_two()\n",
    "test_add_two_to_3()\n",
    "test_add_two_to_minus_6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown"
   },
   "source": [
    "As we have seen, the general solution in this case is kind of trivial. Very often, though, extending something that works for one or two instances to something that works for any possible input is the most challenging part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "def add_two(number: int) -> int:\n",
    "    \"\"\"This function just adds 2 to any number it receives\"\"\"\n",
    "    # START CODE HERE\n",
    "    return number + 2\n",
    "    # END CODE HERE\n",
    "\n",
    "test_add_two()\n",
    "test_add_two_to_3()\n",
    "test_add_two_to_minus_6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous improvements\n",
    "\n",
    "One last benefit of having tests is that we can keep improving them as we go. When developing, you should try to consider not only the general cases, but also all edge cases. Some of them will be easy to think upfront, but in more often than not, you will keep discovering issues as your code is adopted by more people, as it is run against new data, etc...\n",
    "\n",
    "So, what to do when a new edge case (i.e. error, bug) is detected? Well, you should go back to the Red-Green-Refactor cycle, which means that you should start by writing a failing test.\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "Consider the following function along with its test, that calculates your salary. This function will not only check that you don't work overtime (i.e. that you don't get paid for it), but also that your hourly rate is correct (i.e. that you don't earn too much)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHLY_HOURS = 120\n",
    "MAX_HOURLY_RATE = 30.\n",
    "def get_salary(hours: int, hourly_rate: float) -> float:\n",
    "    hours = min(hours, MONTHLY_HOURS)\n",
    "    hourly_rate = min(hourly_rate, MAX_HOURLY_RATE)\n",
    "\n",
    "    return hours * hourly_rate\n",
    "\n",
    "def test_employee_salary():\n",
    "    hours = 120\n",
    "    hourly_rate = 10.\n",
    "    expected_salary = hourly_rate * hours\n",
    "    \n",
    "    salary = get_salary(hours, hourly_rate)\n",
    "    \n",
    "    assert salary == expected_salary, \\\n",
    "        f\"Your salary should be {expected_salary}, but it was {salary}\"\n",
    "\n",
    "def test_hard_working_employee_salary():\n",
    "    hours = 160\n",
    "    hourly_rate = 10.\n",
    "    expected_salary = hourly_rate * MONTHLY_HOURS\n",
    "    \n",
    "    salary = get_salary(hours, hourly_rate)\n",
    "    \n",
    "    assert salary == expected_salary, \\\n",
    "        f\"The salary for the hard-working employee should be {expected_salary}, but it was {salary}\"\n",
    "\n",
    "def test_boss_salary():\n",
    "    hours = 100\n",
    "    hourly_rate = 30.\n",
    "    expected_salary = hourly_rate * hours\n",
    "    \n",
    "    salary = get_salary(hours, hourly_rate)\n",
    "    \n",
    "    assert salary == expected_salary, \\\n",
    "        f\"Your boss' salary should be {expected_salary}, but it was {salary}\"\n",
    "\n",
    "test_employee_salary()\n",
    "test_hard_working_employee_salary()\n",
    "test_boss_salary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it turns that some smart employee found a way to trick the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My salary this month is 12000.0EUR!\n"
     ]
    }
   ],
   "source": [
    "my_salary = get_salary(hours=-120, hourly_rate=-100.)\n",
    "print(f\"My salary this month is {my_salary}EUR!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you have developed the application, your have been asked to fix this error. More precisely, you have been asked to make sure that both hours and hourly_rate are greater than or equal to 0, but never negative.\n",
    "\n",
    "What test(s) do you think you need to add?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we might want to add two tests:\n",
    "\n",
    "- One that verifies that our ```get_salary``` function returns 0 (or throws an exception) when the hours are negative.\n",
    "- One that verifies that our ```get_salary``` function returns 0 (or throws an exception) when the hourly_rate is negative.\n",
    "\n",
    "With these two, we already cover the case when both are negative. Another valid option in this case would be to add just one test case, that asserts that when both hours and hourly_rate are negative, the salary returned is 0. This one is actually what we were asked to do, but will still leave edge cases that might pop up in the future (e.g. when only one of the two is negative).\n",
    "\n",
    "Again, we're providing you the RED part of the TDD cycle, but feel free to update the tests or create your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_negative_hours_mean_no_salary():\n",
    "    hours = -100\n",
    "    hourly_rate = 10.\n",
    "    expected_salary = 0\n",
    "    \n",
    "    salary = get_salary(hours, hourly_rate)\n",
    "    \n",
    "    assert salary == expected_salary, \\\n",
    "        f\"The salary for negative hours should be {expected_salary}, but it was {salary}\"\n",
    "\n",
    "def test_negative_hourly_rate_mean_no_salary():\n",
    "    hours = 50\n",
    "    hourly_rate = -10.\n",
    "    expected_salary = 0\n",
    "    \n",
    "    salary = get_salary(hours, hourly_rate)\n",
    "    \n",
    "    assert salary == expected_salary, \\\n",
    "        f\"The salary for negative hourly rates should be {expected_salary}, but it was {salary}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The salary for negative hours should be 0, but it was -1000.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-5ffed3ff2506>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_negative_hours_mean_no_salary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-9e7e550d7d8b>\u001b[0m in \u001b[0;36mtest_negative_hours_mean_no_salary\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0msalary\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mexpected_salary\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;34mf\"The salary for negative hours should be {expected_salary}, but it was {salary}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtest_negative_hourly_rate_mean_no_salary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: The salary for negative hours should be 0, but it was -1000.0"
     ]
    }
   ],
   "source": [
    "test_negative_hours_mean_no_salary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The salary for negative hourly rates should be 0, but it was -500.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-43a5488e869c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_negative_hourly_rate_mean_no_salary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-7e79aeaa6d44>\u001b[0m in \u001b[0;36mtest_negative_hourly_rate_mean_no_salary\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0msalary\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mexpected_salary\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;34mf\"The salary for negative hourly rates should be {expected_salary}, but it was {salary}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: The salary for negative hourly rates should be 0, but it was -500.0"
     ]
    }
   ],
   "source": [
    "test_negative_hourly_rate_mean_no_salary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, adapt the ```get_salary``` function to pass the new tests (and the old tests as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "MONTHLY_HOURS = 120\n",
    "MAX_HOURLY_RATE = 30.\n",
    "def get_salary(hours: int, hourly_rate: float) -> float:\n",
    "    # START CODE\n",
    "    hours = min(hours, MONTHLY_HOURS)\n",
    "    hourly_rate = min(hourly_rate, MAX_HOURLY_RATE)\n",
    "\n",
    "    return hours * hourly_rate\n",
    "    # END CODE\n",
    "\n",
    "test_employee_salary()\n",
    "test_hard_working_employee_salary()\n",
    "test_boss_salary()\n",
    "test_negative_hours_mean_no_salary()\n",
    "test_negative_hourly_rate_mean_no_salary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "To pass the new tests (while keeping the old tests passing as well), we can just add two new checks to our ```get_salary``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "MONTHLY_HOURS = 120\n",
    "MAX_HOURLY_RATE = 30.\n",
    "CHEATER_SALARY = 0.\n",
    "\n",
    "\n",
    "def get_salary(hours: int, hourly_rate: float) -> float:\n",
    "    if hours < 0:\n",
    "        return CHEATER_SALARY\n",
    "    \n",
    "    if hourly_rate < 0:\n",
    "        return CHEATER_SALARY\n",
    "    \n",
    "    hours = min(hours, MONTHLY_HOURS)\n",
    "    hourly_rate = min(hourly_rate, MAX_HOURLY_RATE)\n",
    "\n",
    "    return hours * hourly_rate\n",
    "    # END CODE\n",
    "\n",
    "test_employee_salary()\n",
    "test_hard_working_employee_salary()\n",
    "test_boss_salary()\n",
    "test_negative_hours_mean_no_salary()\n",
    "test_negative_hourly_rate_mean_no_salary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BDD - Behavior Driven Development\n",
    "\n",
    "BDD tries to make the testing part closer to the business logic, and tests are often expressed in natural language, or in a way that read close to what you would state in natural language. These tests are often defined following the GWT pattern. GWT stands for *Given - When - Then*, and the general definition of a test could be something like:\n",
    "\n",
    "- **Given** some context\n",
    "- **When** some action is performed\n",
    "- **Then** something happens\n",
    "\n",
    "For instance: **given** 1 (an integer number) **when** I add two to it **then** the result should be 3\n",
    "\n",
    "There are some libraries and plugins implementing BDD in Python, such as [behave](https://github.com/behave/behave) or [pytest-bdd](https://pypi.org/project/pytest-bdd/), but we're not covering these types of tests in this course.\n",
    "\n",
    "The cycle when developing using BDD looks somewhat similar to the one using TDD, but it introduces a higher level of abstraction. At this level, often a non-technical user could be able to formulate the test.\n",
    "\n",
    "![BDD Development cycle](../../images/bdd_cycle.jpg \"BDD Development Cycle\")\n",
    "\n",
    "The extra cycle (with the failing scenario, etc) often means that you can define your scenarios more or less directly from user stories / tasks in an Agile context, and your scenarios can be written in a language closer to what the business logic is. GWT is also very common in acceptance tests for instance, where the focus is less on the code itself and more in the result of running it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "625.455px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
